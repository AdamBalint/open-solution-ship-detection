project: USERNAME/PROJECT_NAME

name: airbus_ships_challenge
tags: [solution-1]

metric:
  channel: 'F2'
  goal: maximize

#Comment out if not in Cloud Environment
#pip-requirements-file: requirements.txt

exclude:
  - .git
  - .idea
  - .ipynb_checkpoints
  - output
  - imgs
  - neptune.log
  - offline_job.log
  - notebooks

parameters:
# Data Paths
  train_images_dir: /path/to/data
  test_images_dir:  /path/to/data
  meta_dir:         /path/to/data
  annotation_file:  /path/to/data
  masks_overlayed_dir: /path/to/data 
  experiment_dir:   /path/to/work/dir

  # Execution
  overwrite: 0
  num_workers: 4
  num_threads: 4
  kaggle_message: 'solution_1_small_unet_scratch_no_sampler'
  image_source: disk
  pin_memory: 1
  loader_mode: resize
  pad_method: symmetric
  target_format: 'joblib'
  dev_mode_size: 1000
  n_cv_splits: 10
  shuffle: 1

  # General parameters
  image_h: 128
  image_w: 128
  image_channels: 3
  sample_size: 0
  evaluation_size: 10000
  validation_size: 500
  empty_fraction: 0.1
  valid_empty_fraction: None

  # U-Net parameters
  unet_output_channels: 2
  unet_activation: 'sigmoid'
  encoder: from_scratch

  # U-Net from scratch parameters
  nr_unet_outputs: 1
  n_filters: 8
  conv_kernel: 3
  pool_kernel: 3
  pool_stride: 2
  repeat_blocks: 3

  # Loss
  dice_weight: 5.0
  bce_weight: 1.0

  # Training schedule
  epochs_nr: 100
  batch_size_train: 160
  batch_size_inference: 500
  lr: 0.0001
  momentum: 0.9
  gamma: 0.95
  patience: 5
  validation_metric_name: 'f2'
  minimize_validation_metric: 0

  # Regularization
  use_batch_norm: 1
  l2_reg_conv: 0.0001
  l2_reg_dense: 0.0
  dropout_conv: 0.1
  dropout_dense: 0.0

  # Postprocessing
  threshold_masks: 0.5
  tta_aggregation_method: mean
